{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import find_peaks, butter, filtfilt, welch\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Config\n",
    "FPS = 30\n",
    "DURATION = 30\n",
    "WINDOW_SIZE = 90\n",
    "STEP_SIZE = 45\n",
    "MIN_SAMPLES = 5\n",
    "METRICS = ['heart_rate', 'hrv', 'resp_rate', 'pulse_amp']\n",
    "VALIDATION_RATIO = 0.2\n",
    "DRIFT_THRESHOLD = 0.15  # Concept drift threshold (MSE increase)\n",
    "\n",
    "# Historical MSE for drift tracking\n",
    "history_mse = {metric: [] for metric in METRICS}\n",
    "\n",
    "def record_video(filename='ppg_capture.avi', duration=DURATION, fps=FPS):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width, height = int(cap.get(3)), int(cap.get(4))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
    "    print(f\"Recording for {duration} seconds. Cover camera with your fingertip.\")\n",
    "    start_time = time.time()\n",
    "    while (time.time() - start_time) < duration:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        remaining = max(0, int(duration - (time.time() - start_time)))\n",
    "        cv2.putText(frame, f\"Recording: {remaining}s\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Recording (Press Q to stop)', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_signal(signal, fps):\n",
    "    nyq = 0.5 * fps\n",
    "    b, a = butter(2, [0.5/nyq, 4.0/nyq], btype='band')\n",
    "    filtered = filtfilt(b, a, signal)\n",
    "    return (filtered - np.mean(filtered)) / np.std(filtered)\n",
    "\n",
    "def extract_features(signal, fps):\n",
    "    processed = process_signal(signal, fps)\n",
    "    features = []\n",
    "    for i in range(0, len(processed) - WINDOW_SIZE, STEP_SIZE):\n",
    "        window = processed[i:i+WINDOW_SIZE]\n",
    "        fft = np.abs(np.fft.fft(window))\n",
    "        freqs = np.fft.fftfreq(len(window), 1/fps)\n",
    "        features.append([\n",
    "            np.mean(window),\n",
    "            np.std(window),\n",
    "            freqs[np.argmax(fft)],\n",
    "            np.sum(fft**2),\n",
    "            len(find_peaks(window)[0]),\n",
    "            np.percentile(window, 75)\n",
    "        ])\n",
    "    return np.array(features)\n",
    "\n",
    "def traditional_measures(signal, fps):\n",
    "    smoothed = gaussian_filter1d(signal - np.mean(signal), 2)\n",
    "    peaks, _ = find_peaks(smoothed, distance=fps * 0.5)\n",
    "    duration_secs = len(signal) / fps\n",
    "    hr = len(peaks) / duration_secs * 60\n",
    "    rr_intervals = np.diff(peaks) / fps * 1000\n",
    "    hrv = np.std(rr_intervals)\n",
    "    freqs, psd = welch(smoothed, fs=fps, nperseg=256)\n",
    "    resp_band = (freqs > 0.1) & (freqs < 0.5)\n",
    "    resp_rate = freqs[resp_band][np.argmax(psd[resp_band])] * 60\n",
    "    pulse_amplitude = np.max(smoothed) - np.min(smoothed)\n",
    "    return hr, hrv, resp_rate, pulse_amplitude\n",
    "\n",
    "def load_or_init_models(metrics):\n",
    "    models = {}\n",
    "    for metric in metrics:\n",
    "        model_file = f\"{metric}_model.pkl\"\n",
    "        if os.path.exists(model_file):\n",
    "            models[metric] = joblib.load(model_file)\n",
    "        else:\n",
    "            model = make_pipeline(\n",
    "                StandardScaler(),\n",
    "                SGDRegressor(learning_rate='adaptive', eta0=0.01, power_t=0.25, warm_start=True)\n",
    "            )\n",
    "            models[metric] = model\n",
    "    return models\n",
    "\n",
    "def train_models_online(models, X, y_true, val_X, val_y):\n",
    "    for i, metric in enumerate(METRICS):\n",
    "        model = models[metric]\n",
    "        scaler = model.named_steps['standardscaler']\n",
    "        regressor = model.named_steps['sgdregressor']\n",
    "\n",
    "        if not hasattr(scaler, 'mean_'):\n",
    "            scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        val_X_scaled = scaler.transform(val_X)\n",
    "\n",
    "        for x_scaled in X_scaled:\n",
    "            regressor.partial_fit(x_scaled.reshape(1, -1), [y_true[i]])\n",
    "\n",
    "        preds = regressor.predict(val_X_scaled)\n",
    "        val_target = np.array([val_y[i]] * len(val_X_scaled))\n",
    "        mse = mean_squared_error(val_target, preds)\n",
    "        history_mse[metric].append(mse)\n",
    "\n",
    "        print(f\"[Validation] {metric} MSE: {mse:.4f}\")\n",
    "\n",
    "        if len(history_mse[metric]) >= 5:\n",
    "            recent = history_mse[metric][-3:]\n",
    "            old_avg = np.mean(history_mse[metric][:-3])\n",
    "            recent_avg = np.mean(recent)\n",
    "            if old_avg and abs(recent_avg - old_avg) / old_avg > DRIFT_THRESHOLD:\n",
    "                print(f\"[Drift Warning] Significant change in '{metric}' performance. Consider model reset or retraining.\")\n",
    "\n",
    "        joblib.dump(model, f\"{metric}_model.pkl\")\n",
    "\n",
    "def predict_metrics(models, X):\n",
    "    predictions = {}\n",
    "    X_avg = X.mean(axis=0).reshape(1, -1)\n",
    "    for metric in METRICS:\n",
    "        predictions[metric] = models[metric].predict(X_avg)[0]\n",
    "    return predictions\n",
    "\n",
    "def evaluate_model(preds, truths):\n",
    "    print(\"\\n--- Model Evaluation (vs Traditional) ---\")\n",
    "    for i, metric in enumerate(METRICS):\n",
    "        true_val = truths[i]\n",
    "        pred_val = preds[metric]\n",
    "        mae = mean_absolute_error([true_val], [pred_val])\n",
    "        mse = mean_squared_error([true_val], [pred_val])\n",
    "        rel_error = abs(true_val - pred_val) / true_val * 100 if true_val != 0 else 0\n",
    "\n",
    "        print(f\"{metric.capitalize()}:\")\n",
    "        print(f\"  MAE         = {mae:.2f}\")\n",
    "        print(f\"  MSE         = {mse:.2f}\")\n",
    "        print(f\"  Relative Error (%) = {rel_error:.2f}%\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "record_video()\n",
    "\n",
    "cap = cv2.VideoCapture('ppg_capture.avi')\n",
    "signal_data = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cyan_signal = np.mean(frame[:, :, [0, 1]], axis=2)  # Cyan = average of blue and green\n",
    "    signal_data.append(np.mean(cyan_signal))\n",
    "cap.release()\n",
    "signal_data = np.array(signal_data)\n",
    "\n",
    "X_new = extract_features(signal_data, fps=FPS)\n",
    "if len(X_new) < MIN_SAMPLES:\n",
    "    raise ValueError(f\"Need at least {MIN_SAMPLES} windows. Got {len(X_new)}\")\n",
    "\n",
    "split_idx = int((1 - VALIDATION_RATIO) * len(X_new))\n",
    "X_train, X_val = X_new[:split_idx], X_new[split_idx:]\n",
    "\n",
    "true_vals = traditional_measures(signal_data, fps=FPS)\n",
    "models = load_or_init_models(METRICS)\n",
    "train_models_online(models, X_train, true_vals, X_val, true_vals)\n",
    "\n",
    "ml_preds = predict_metrics(models, X_new)\n",
    "\n",
    "print(\"\\n--- PPG Analysis Results (Traditional) ---\")\n",
    "print(f\"Heart Rate (BPM): {true_vals[0]:.2f}\")\n",
    "print(f\"Heart Rate Variability (ms): {true_vals[1]:.2f}\")\n",
    "print(f\"Respiratory Rate (breaths/min): {true_vals[2]:.2f}\")\n",
    "print(f\"Pulse Amplitude: {true_vals[3]:.2f}\")\n",
    "\n",
    "print(\"\\n--- ML Predictions ---\")\n",
    "print(f\"Heart Rate (BPM): {ml_preds['heart_rate']:.2f}\")\n",
    "print(f\"Heart Rate Variability (ms): {ml_preds['hrv']:.2f}\")\n",
    "print(f\"Respiratory Rate (breaths/min): {ml_preds['resp_rate']:.2f}\")\n",
    "print(f\"Pulse Amplitude: {ml_preds['pulse_amp']:.2f}\")\n",
    "\n",
    "evaluate_model(ml_preds, true_vals)\n",
    "\n",
    "# Plot signal and peaks\n",
    "smoothed_signal = gaussian_filter1d(signal_data - np.mean(signal_data), sigma=2)\n",
    "peaks, _ = find_peaks(smoothed_signal, distance=FPS * 0.5)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(smoothed_signal, label='Smoothed PPG Signal (Cyan)', color='c')\n",
    "plt.plot(peaks, smoothed_signal[peaks], 'rx', label='Detected Peaks')\n",
    "plt.title(\"Traditional PPG Signal Analysis\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Filtered Cyan Channel Intensity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
